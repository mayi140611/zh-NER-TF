{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os, argparse, time, random\n",
    "from utils import str2bool, get_logger, get_entity\n",
    "from data import read_corpus, read_dictionary, tag2label, random_embedding\n",
    "\n",
    "from model import BiLSTM_CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Session configuration\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # default: 0\n",
    "config = tf.ConfigProto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## paths setting\n",
    "paths = {}\n",
    "timestamp='1526890202'\n",
    "output_path = os.path.join('.', 'data_path'+\"_save\", timestamp)\n",
    "if not os.path.exists(output_path): os.makedirs(output_path)\n",
    "summary_path = os.path.join(output_path, \"summaries\")\n",
    "paths['summary_path'] = summary_path\n",
    "if not os.path.exists(summary_path): os.makedirs(summary_path)\n",
    "model_path = os.path.join(output_path, \"checkpoints/\")\n",
    "if not os.path.exists(model_path): os.makedirs(model_path)\n",
    "ckpt_prefix = os.path.join(model_path, \"model\")\n",
    "paths['model_path'] = ckpt_prefix\n",
    "result_path = os.path.join(output_path, \"results\")\n",
    "paths['result_path'] = result_path\n",
    "if not os.path.exists(result_path): os.makedirs(result_path)\n",
    "log_path = os.path.join(result_path, \"log.txt\")\n",
    "paths['log_path'] = log_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 3905\n"
     ]
    }
   ],
   "source": [
    "## get char embeddings\n",
    "word2id = read_dictionary(os.path.join('.', 'data_path', 'word2id.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.load('pretrain_embedding.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = os.path.join('.', 'data_path', 'test_data')\n",
    "test_data = read_corpus(test_path)\n",
    "test_size = len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\data_path_save\\1526890202\\checkpoints/model-31680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ian\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "=========== testing ===========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data: 4631\n",
      "INFO:tensorflow:Restoring parameters from .\\data_path_save\\1526890202\\checkpoints/model-31680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring parameters from .\\data_path_save\\1526890202\\checkpoints/model-31680\n"
     ]
    }
   ],
   "source": [
    "## testing model\n",
    "# elif args.mode == 'test':\n",
    "#     ckpt_file = tf.train.latest_checkpoint(model_path)\n",
    "#     print(ckpt_file)\n",
    "#     paths['model_path'] = ckpt_file\n",
    "#     model = BiLSTM_CRF(args, embeddings, tag2label, word2id, paths, config=config)\n",
    "#     model.build_graph()\n",
    "#     print(\"test data: {}\".format(test_size))\n",
    "#     model.test(test_data)\n",
    "## testing model\n",
    "ckpt_file = tf.train.latest_checkpoint(model_path)\n",
    "print(ckpt_file)\n",
    "paths['model_path'] = ckpt_file\n",
    "model = BiLSTM_CRF(embeddings, tag2label, word2id, paths, config=config)\n",
    "model.build_graph()\n",
    "print(\"test data: {}\".format(test_size))\n",
    "model.test(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\data_path_save\\1526890202\\checkpoints/model-31680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ian\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= demo =============\n",
      "INFO:tensorflow:Restoring parameters from .\\data_path_save\\1526890202\\checkpoints/model-31680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring parameters from .\\data_path_save\\1526890202\\checkpoints/model-31680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please input your sentence:\n",
      "詹姆斯已经命中了6次投篮，生涯季后赛命中数超越天勾贾巴尔，升至历史第一\n",
      "PER: ['詹姆斯', '贾巴尔']\n",
      "LOC: []\n",
      "ORG: []\n",
      "Please input your sentence:\n",
      "大家好，我叫刘知远，来自清华大学计算机系。非常感谢前面李涓子老师、蔡老师讲了一些认知和知识图谱相关的知识，这样我就可以接着他们讲我今天的题目。我的题目是：表示学习跟大家耳熟能详的深度学习有密切的联系。\n",
      "PER: ['刘知远', '李涓子', '蔡']\n",
      "LOC: []\n",
      "ORG: ['清华大学']\n",
      "Please input your sentence:\n",
      "大家好，我叫刘知远，我的籍贯是山西省晋中市祁县，来自清华大学计算机系。非常感谢前面李涓子老师、蔡老师讲了一些认知和知识图谱相关的知识，这样我就可以接着他们讲我今天的题目。我的题目是：表示学习跟大家耳熟能详的深度学习有密切的联系。\n",
      "PER: ['刘知远', '李涓子', '蔡']\n",
      "LOC: ['山西省', '晋中市', '祁县']\n",
      "ORG: ['清华大学']\n",
      "Please input your sentence:\n",
      "大家好，我叫刘知远，我的籍贯是山西省晋中市祁县的西六支乡里面的王村，来自清华大学计算机系。非常感谢前面李涓子老师、蔡刚刚老师讲了一些认知和知识图谱相关的知识，这样我就可以接着他们讲我今天的题目。我的题目是：表示学习跟大家耳熟能详的深度学习有密切的联系。\n",
      "PER: ['刘知远', '李涓子', '蔡刚刚']\n",
      "LOC: ['山西省', '晋中市', '祁县', '王村']\n",
      "ORG: ['清华大学计算机系']\n",
      "Please input your sentence:\n",
      "大家好，我叫刘知远，我的籍贯是山西省晋中市祁县的西六支乡的王村，来自清华大学计算机系。我的儿子是祁县公安局局长。非常感谢前面李涓子老师、蔡刚刚老师讲了一些认知和知识图谱相关的知识，这样我就可以接着他们讲我今天的题目。我的题目是：表示学习跟大家耳熟能详的深度学习有密切的联系。\n",
      "PER: ['刘知远', '王村', '李涓子', '蔡刚刚']\n",
      "LOC: ['山西省', '晋中市', '祁县', '西六支乡']\n",
      "ORG: ['清华大学', '祁县公安局']\n",
      "Please input your sentence:\n",
      "\n",
      "See you next time!\n"
     ]
    }
   ],
   "source": [
    "## demo\n",
    "ckpt_file = tf.train.latest_checkpoint(model_path)\n",
    "print(ckpt_file)\n",
    "paths['model_path'] = ckpt_file\n",
    "model = BiLSTM_CRF(embeddings, tag2label, word2id, paths, config=config)\n",
    "model.build_graph()\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session(config=config) as sess:\n",
    "    print('============= demo =============')\n",
    "    saver.restore(sess, ckpt_file)\n",
    "    while(1):\n",
    "        print('Please input your sentence:')\n",
    "        demo_sent = input()\n",
    "        if demo_sent == '' or demo_sent.isspace():\n",
    "            print('See you next time!')\n",
    "            break\n",
    "        else:\n",
    "            demo_sent = list(demo_sent.strip())\n",
    "            demo_data = [(demo_sent, ['O'] * len(demo_sent))]\n",
    "            tag = model.demo_one(sess, demo_data)\n",
    "            PER, LOC, ORG = get_entity(tag, demo_sent)\n",
    "            print('PER: {}\\nLOC: {}\\nORG: {}'.format(PER, LOC, ORG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\data_path_save\\1526890202\\checkpoints/model-31680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ian\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= demo =============\n",
      "INFO:tensorflow:Restoring parameters from .\\data_path_save\\1526890202\\checkpoints/model-31680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring parameters from .\\data_path_save\\1526890202\\checkpoints/model-31680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please input your sentence:\n",
      "大家好，我叫刘环环，我的籍贯是山西省晋中市祁县西六支乡王村，来自清华大学计算机系。我的儿子是祁县公安局局长。我老婆在祁县人民医院工作，我孙子在王村小学教书，非常感谢前面李涓子老师、蔡刚刚老师讲了一些认知和知识图谱相关的知识，这样我就可以接着他们讲我今天的题目。我的题目是：表示学习跟大家耳熟能详的深度学习有密切的联系。\n",
      "PER: ['刘环环', '李涓子', '蔡刚刚']\n",
      "LOC: ['山西省', '晋中市', '祁县', '西六支乡', '王村']\n",
      "ORG: ['清华大学', '祁县公安局', '祁县人民医院']\n",
      "Please input your sentence:\n",
      "我孙子在王村小学教书\n",
      "PER: []\n",
      "LOC: []\n",
      "ORG: []\n",
      "Please input your sentence:\n",
      "我孙子在西电教书\n",
      "PER: []\n",
      "LOC: []\n",
      "ORG: []\n",
      "Please input your sentence:\n",
      "我孙子在西安电子科技大学教书\n",
      "PER: []\n",
      "LOC: []\n",
      "ORG: ['西安电子科技大学']\n",
      "Please input your sentence:\n",
      "\n",
      "See you next time!\n"
     ]
    }
   ],
   "source": [
    "ckpt_file = tf.train.latest_checkpoint(model_path)\n",
    "print(ckpt_file)\n",
    "paths['model_path'] = ckpt_file\n",
    "model = BiLSTM_CRF(embeddings, tag2label, word2id, paths, config=config)\n",
    "model.build_graph()\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session(config=config) as sess:\n",
    "    print('============= demo =============')\n",
    "    saver.restore(sess, ckpt_file)\n",
    "    while(1):\n",
    "        print('Please input your sentence:')\n",
    "        demo_sent = input()\n",
    "        if demo_sent == '' or demo_sent.isspace():\n",
    "            print('See you next time!')\n",
    "            break\n",
    "        else:\n",
    "            demo_sent = list(demo_sent.strip())\n",
    "            demo_data = [(demo_sent, ['O'] * len(demo_sent))]\n",
    "            tag = model.demo_one(sess, demo_data)\n",
    "            PER, LOC, ORG = get_entity(tag, demo_sent)\n",
    "            print('PER: {}\\nLOC: {}\\nORG: {}'.format(PER, LOC, ORG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
